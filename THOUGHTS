== Random stuff ==

* POSIX: JNI, JNA, external process?
** JNI/JNA is annoying for build reasons. External process for communication reasons, but siomple to provide a portable .c file + Makefile.
** Would always be possible to use shastity without native integration for doing things like just backing up a hierarchy of images where you don't care.
* Release: Make official .jar releases with no dependency other than JDK (and C compiler for native parts if needed).
** Users to be encouraged to store such things safely with their backups or elsewhere to not depend on github/upstream.

== Block PUT scheduling ==

If there are many small blocks and many big blocks in the queue, they should
be scheduled so that big ones run in the background while the small ones
pop in and out. This is because big blocks are limited by bandwidth and small
ones by latency.

A fairly simple algorithm here might be to have two logical queues;
one for small items and one for big ones.

It would have the nice benefit that the concurrency can be kept high
for latency critical aspects that are cheap (in terms of memory) to
keep highly concurrent, while limiting extreme concurrencies for big
data that might cause memory to become a bottleneck in trying to
achieve wire speeds.

A problem is that it means that once one queue is full, a persist
process must still continue and not block on the queue. So it will
have to queue up stuff to be done later in a safe way that doesn't
cause memory consumption issues.

I think a good first solution is to not introduce complexity at all,
and just have a concurrency which is defined by memory use and have
that limit be at least N times the block size, N being the concurrency
needed to saturate whatever you want to saturate when transfering
large files. This will mean that concurrency is actually continuously
dynamic depending on the size of things being uploaded - though of
course subject to some maximum hard concurrency limit which may be
relevant depending on backend.

== GC ==
In order to GC you need access to all crypto keys, or you won't be able to
read the manifests to know what blocks are in use, and you won't know the
encrypted names of the blocks when you want to delete them.

== Crypto ==
Use GPG for data encryption? KeyCzar?
Manifest could contain which crypto wrapper to use for a given block.
That way you don't have to re-upload if you change your mind.

UPDATE: KeyCzar doesn't seem very alive, people have issues with it,
and format isn't guaranteed. GPG is out because of shell tool reasons
among other things. Let's just go for using standard Java crypto and
doing our own, at the cost of having to get some input from crypto
people to confirm with reasonable certainty that we're doing things
correctly from a security standpoint.

Should provide an easy way (cmdline options) for someone to decrypt
and encrypt individual blocks independently of the persist/depersist
process. Should also be exposed as a library so that a developer can
easily write a tool that does encryption/decryption without
re-factoring the shastity code base...

== Amazon MD5 ==
Store MD5 as amazon metadata.
Also double-check when materializing.

UPDATE: Why? (Split people editing this file.) We have our own
checksum anyway. But yes, MD5 should certainly be set during the
upload process by the S3 backend. But I don't see a need to consider
backend specific checksumming outside of the backend.

== Manifest format ==
Primary goals are:

* (1) Very easy to manually inspect/use/understand and deal with via shell tools
* (2) Must scale to large backups (hundreds of millions of files)
* (3) Must scale to large individual files (at least 1 TB)

We will propose a file format and then look at how the requirements
are fulfilled.

Let us apply compression (e.g. gzip, or bzip2, or blocked gzip) to the
entire file so we do not need to be very careful about being verbose
as long as it's repeated and compressible.

Let's have the manifest be line-oriented, and start with a single
line:

  # shastity 1.0 manifest

And let's have the final line be (containing hex digest of all preceeding data):

  # shastity 1.0 manifest hexdigest HEXHEXHEX

In between, a list of lines, sorted on path, of:

  $path $meta $hash1 $hash2 ... $hashN

Assume that path and meta are both encoded with a simple escaping
mechanism to eliminate any whitespace and generally non-ascii stuff
for easy handling in a shell.

Further:

* path is the plain path
* meta is a not-so-human-readable data structure (probably a clojure map) of
  meta-data; here we can stuff arbitrary stuff in an extensible manner without
  breaking basic simplicity. having "arbitrary blob" means that from a development
  standpoint we don't need a lot of code to handle this, and can just serialize a clojure
  data structure - done. it's still not super-opaque though if someone is truly in a pinch.
* hashes are hexdigests
* there may be zero hashes (e.g., in the case of a symlink)

How does this stack up?

(1) is very well catered do. You can obtain a list of blocks to append
to construct a file by doing stuff like:

  `cat manifest | egrep ^/path/to/file\ | tr \ \\n | tail -n +3`

And restoring it is as easy as:

  `for block in $(cat manifest | egrep ^/path/to/file\ | tr \ \\n | tail -n +3) ; do store-get $block >> file ; done`

Assuming `store-get` is something which grabs a block from
store. Obviously slight adjustments may be necessary.

(2) mainly has to do with the size and handling of a manifest. A very
non-scientific test is a "find ." in my home directory containing a
mix of manually cared-for data files and stuff like vcs checkouts of
non-trivial projects like openjdk. I had 347 thousand files, and the
file listing became 28 MB in size. After gzip compression it's down to
2.1 MB. Let's say that a 10x compression ratio is pretty okay. Let's
further arbitrarily use 100 million files as a test case. Let's assume
the typical path is roughly 50 bytes long, and is compressible by 10x
by gzip.

With those numbers, 100 million paths translate into 476 MBs of
manifest data for the paths. Even assuming a total data size of 1k per
file including fs overhead, that's pretty reasonable (< 1% of data is
manifest data).

hexdigests are another matter, but can be efficiently tweaked
depending on what's being backed up and there is an obvious
relationship between block size and manifest size. If you truly have
huge files with a huge number of changes spread out and want a small
block size - then yeah, you're going to have to have a lot of meta
data. Tough. :)

So (3), already touched upon: We're fine. Let's assume a 1 TB file and
a 5 MB block size. That's roughly 200k of memory per hexdigest byte or
8 MB of text assuming 40 byte hex digests. This is *quite* reasonable
to have as a single line of text; shells won't explode, memory use
won't explode when doing a read-line operation in code, etc.

So, with the only streaming need being to stream the entire file, we
can treat each line in the file as an object and process it with
reasonable memory use. We are using a reasonable amount of disk space
and bandwidth for the manifests in relation to the amount of data and
the amount of files being backed up.

We have no O(n) memory use for any N which is not "reasonably
bounded".

For incremental backups, nothing prevents from using the manifest
format incrementally to some extent (though it adds complexity and
makes manifests non-standalone). Typical use-case should probably be
non-incremental, but incremental would be nice when e.g. doing
continuous backups based on file system change monitoring and things
like that.

(See manifest de-duplication section too)

== Ensuring backup consistency ==

There are some nice things that are possible given shastity's data
model. We can verify integrity of individual blocks indepdendently of
others; so we can do things like probabilistically sampling 0.1% of
blocks and report any problems to the user. This offers a good way to
detect systematic problems in the storage backend that affect a
non-trivial amount of data, without actually needing to read
everything from the store.

Such a test can also be made in a deterministically forward fashion;
e.g. test 1% of blocks every day in such a way that after 100 days
everything has been tested.

The same goes for manifests, being very "independent". They can be
checked for consistency either fully or probabilistically.

So; we have some good basics for doing intelligent things. Those
things need to be implement too of course. Some potential features to
have:

* "shastity random-blob-consistency-check 1%" - check 1% pseudo-random blocks in store
* "shastity rolling-blob-consistency-check 57/100" - check 1% of blobs in a 100-step process, this being step 57
* "shastity random-manifest-check 1%"
* "shastity rolling-manifest-check 57/100"
* "shastity compare" - attempt to compare on-disk state with manifest.
* When operating in a mode which elides checksumming for files whose meta-data matches that of a previous
  manifest, we can support probabilistically hashing anyway such that the user can hope to detect cases
  where the performance optimzation is broken.

== Performance/system issues ==

* We could support use of mincore() and posix_fadvise() to try to avoid evicting page cache.
* We could support rate limited reads from disk.
* We SHOULD be able to operate in a "native" mode where we accurately traverse directories
  using proper use of the posix API, to not be vulnerable to volatile paths or metadata/data.
  Until this is supported, use of file system snapshots (which is recommended anyway) eliminates
  this problem.

== Scalable use at organizations ==

* We could support using the same blob store for independent collections of manifests. We must however
  be careful about garbage collection.
* We could support sharding over multiple blob stores to facilitate easy scalability by adding servers
  without complex operations. We can even support this without requireing some kind of stop-and-copy-and-start
  process by being consciece during reads of potential locations of data. Use consistent hashing. Means copying
  a lot of data in between hosts, but makes it trivial and devoid of a bunch of meta data and consistency concerns.

== Manifest de-duplication ==

* Someone pointed out that the menifest is subjectible to
  de-duplication as well. My first thought was to divide it into
  lexicographic (by pathname) "chunks" and hope that granularity will
  be good enough. But this could get complex. The I realized... let's
  just adjust the manifest to be a tree (git style). Done. So freaking
  beautiful. It all just automatically clicks. We get de-duplication
  at a very natural level. If we want to cater to the case of a single
  directory having a huge number of files in it - no problem, let's
  just do a b-tree style division.
* Helps concurrent in manifest upload/download.
* No single huge manifest file.
* Manifest is not as trivial anymore :(
* Naive mapping scales linearly with the amount of directories. But on the other hand, we
  already accept one bucket file per file system file, and further imposing one file per directory
  seems like a non-problem.
* Because the manifest would now be effectively a tree, we not become
  very latency sensitive when traversing the manifest in order.
* Given that we also might want to be smart about large directories, maybe one should just build a btree
  over a sorted list of paths rather than tie anything to directory structure. But a downside of that
  is that we don't get "natural" points of de-dup automatically, which we would otherwise get.
* A tree node per directory means that directories with few entries effectively yield a tree with
  a low branching factor. This is primarily a potential issue in our case for concurrency reasons
  when traversing the tree.
* Hmmm. :/
* UPDATE: Here is the killer problem though: It drops the property of the manifest as being inherently
  self-contained and redundant.
* On the other hand, one could still use this method for incrementals.
* Another problem: Reconstructing the sorted manifest is inherently a depth-first traversal.
* On the *other* hand, if we go for this representation of a manifest, there is no longer a need *to*
  treat the manifest as a sorted list at all to begin with.

== Other stuff ==
* potentially multiple levels
* splitting manifest also good for easy concurrent upload/download

* should have built-in support for keeping the "secret" along with the
  remote backups using password based encryption.